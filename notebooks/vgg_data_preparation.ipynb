{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from retinaface import RetinaFace\n",
    "\n",
    "# Set the path to the VGGFace2 dataset\n",
    "orig_dir = \"I:/vggface2\"\n",
    "\n",
    "# Set the path to the directory where you want to copy the selected images\n",
    "new_dir = \"I:/balanced_vggface2\"\n",
    "\n",
    "# Set the path to the text file to save the selected file paths\n",
    "txt_path = \"I:/files.txt\"\n",
    "\n",
    "# Set the number of images to select per person\n",
    "num_images = 40\n",
    "\n",
    "# Create a list to store the selected file paths\n",
    "selected_files = []\n",
    "\n",
    "# Create the new directory if it doesn't exist\n",
    "if not os.path.exists(new_dir):\n",
    "    os.makedirs(new_dir)\n",
    "\n",
    "# Initialize the MTCNN face detector\n",
    "# detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9131/9131 [19:11:25<00:00,  7.57s/it]   \n"
     ]
    }
   ],
   "source": [
    "for person_dir in tqdm(os.listdir(orig_dir)):\n",
    "    if os.path.isdir(os.path.join(orig_dir, person_dir)):\n",
    "        # print(\"Processing person:\", person_dir)\n",
    "        images = os.listdir(os.path.join(orig_dir, person_dir))\n",
    "        selected_images = np.random.choice(images, size=num_images, replace=False)\n",
    "\n",
    "        # Create the new directory for this person\n",
    "        person_new_dir = os.path.join(new_dir, person_dir)\n",
    "        if not os.path.exists(person_new_dir):\n",
    "            os.makedirs(person_new_dir)\n",
    "\n",
    "        # Loop through the selected images and detect and save the faces\n",
    "        for image_name in selected_images:\n",
    "            # Load the image\n",
    "            image_path = os.path.join(orig_dir, person_dir, image_name)\n",
    "            person_new_dir = os.path.join(new_dir, person_dir)\n",
    "            # image = tf.io.read_file(image_path)\n",
    "            # image = tf.image.decode_jpeg(image)\n",
    "\n",
    "            # Detect faces using MTCNN\n",
    "            # result = detector.detect_faces(image.numpy())\n",
    "            # result = RetinaFace.detect_faces(image.numpy())\n",
    "            faces = RetinaFace.extract_faces(img_path=image_path, align=True)\n",
    "            # if len(result.keys()) != 1:\n",
    "            if len(faces) != 1:\n",
    "                # Skip images with no face or more than one face detected\n",
    "                # print(\"Skipped image:\", image_name, \"for person:\", person_dir)\n",
    "                continue\n",
    "\n",
    "            # Crop and save the face\n",
    "            # face = result['face_1']['facial_area'] #[0][\"box\"]\n",
    "            face_image = faces[0]\n",
    "            # x1, y1, w, h = face\n",
    "            # x2, y2 = x1 + w, y1 + h\n",
    "            # face_image = image[y1:y2, x1:x2]\n",
    "            resized_image = tf.image.resize(face_image, [112, 112])\n",
    "            resized_image = tf.cast(resized_image, tf.uint8)  # Convert float tensor to uint8 tensor\n",
    "            face_path = os.path.join(person_new_dir, image_name)\n",
    "            tf.io.write_file(face_path, tf.image.encode_jpeg(resized_image))\n",
    "            selected_files.append(face_path)\n",
    "\n",
    "# Save the selected file paths to the text file\n",
    "with open(txt_path, \"w\") as f:\n",
    "    for path in selected_files:\n",
    "        f.write(path + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete ids with less than 30 images and keep only 30 images for each id\n",
    "import random\n",
    "\n",
    "# Set the minimum number of images per class\n",
    "min_images_per_class = 30\n",
    "\n",
    "# Loop through each subdirectory (i.e., class) in the dataset directory\n",
    "for class_dir in tqdm(os.listdir(new_dir)):\n",
    "    # Get the path to the current class directory\n",
    "    class_path = os.path.join(new_dir, class_dir)\n",
    "    \n",
    "    # Check if the current path is a directory (to avoid files)\n",
    "    if os.path.isdir(class_path):\n",
    "        # Get the list of all image files in the current class directory\n",
    "        image_files = [os.path.join(class_path, f) for f in os.listdir(class_path) if f.endswith('.jpg') or f.endswith('.png') or f.endswith('.jpeg')]\n",
    "        # If the number of images is less than the minimum, delete the entire class directory\n",
    "        if len(image_files) < min_images_per_class:\n",
    "            print('deleting' , class_dir)\n",
    "            shutil.rmtree(class_path)\n",
    "            # If the number of images is greater than or equal to the minimum, randomly select 30 and delete the rest\n",
    "        else:\n",
    "            # Shuffle the list of image files randomly\n",
    "            random.shuffle(image_files)\n",
    "            \n",
    "            # Delete all image files after the first 30\n",
    "            for file_path in image_files[min_images_per_class:]:\n",
    "                os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8907"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(new_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8907/8907 [22:57<00:00,  6.47it/s] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set the paths to your image dataset folders\n",
    "data_dir = \"I:/balanced_vggface2\"\n",
    "train_dir = 'I:/balanced_vggface2/train'\n",
    "test_dir = 'I:/balanced_vggface2/test'\n",
    "val_dir = 'I:/balanced_vggface2/val'\n",
    "\n",
    "# Set the number of images you want for each category\n",
    "num_train = 20\n",
    "num_test = 5\n",
    "num_val = 5\n",
    "\n",
    "# Get the list of classes in your dataset\n",
    "classes = os.listdir(data_dir)\n",
    "\n",
    "# Create the train, test, and val folders if they don't already exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each class and copy the images to the appropriate folders\n",
    "for class_name in tqdm(classes):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    images = os.listdir(class_path)\n",
    "    random.shuffle(images)  # Shuffle the list of images\n",
    "    \n",
    "    # Copy images to the train folder\n",
    "    for image in images[:num_train]:\n",
    "        src_path = os.path.join(class_path, image)\n",
    "        dst_path = os.path.join(train_dir, class_name, image)\n",
    "        os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "    \n",
    "    # Copy images to the test folder\n",
    "    for image in images[num_train:num_train+num_test]:\n",
    "        src_path = os.path.join(class_path, image)\n",
    "        dst_path = os.path.join(test_dir, class_name, image)\n",
    "        os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "    \n",
    "    # Copy images to the validation folder\n",
    "    for image in images[num_train+num_test:num_train+num_test+num_val]:\n",
    "        src_path = os.path.join(class_path, image)\n",
    "        dst_path = os.path.join(val_dir, class_name, image)\n",
    "        os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "        shutil.copy(src_path, dst_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dianat\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.8.0 and strictly below 2.11.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.11.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import warnings\n",
    "from onnx_tf.backend import prepare\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "# all_ids = np.load('./id_files/glint_all_ids.npz')['res']\n",
    "# warnings.filterwarnings('ignore') # Ignore all the warning messages in this tutorial\n",
    "\n",
    "onnx_model = onnx.load('F:/test/onnx_tensorflow/model.onnx')\n",
    "tf_rep = prepare(onnx_model) # Import the ONNX model to Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8910/8910 [00:03<00:00, 2669.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "# Set the path to the directory where you want to copy the selected images\n",
    "new_dir = \"I:/balanced_vggface2\"\n",
    "\n",
    "all_ids_dict = dict()\n",
    "\n",
    "for id in tqdm(os.listdir(new_dir)):\n",
    "    if id in ['train', 'test', 'val']:\n",
    "        continue\n",
    "    all_ids_dict[id] = {'train':[], 'test':[], 'val':[]}\n",
    "    for file in os.listdir(os.path.join(new_dir, 'train', id)):\n",
    "        all_ids_dict[id]['train'].append(os.path.join(new_dir, 'train', id, file))\n",
    "    for file in os.listdir(os.path.join(new_dir, 'test', id)):\n",
    "        all_ids_dict[id]['test'].append(os.path.join(new_dir, 'test', id, file))\n",
    "    for file in os.listdir(os.path.join(new_dir, 'val', id)):\n",
    "        all_ids_dict[id]['val'].append(os.path.join(new_dir, 'val', id, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "os.makedirs(os.path.join('.', 'vggface2'))\n",
    "with open(os.path.join('.', 'vggface2', 'all_id_files.json'), 'w') as fp:\n",
    "    json.dump(all_ids_dict, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(all_ids_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8907/8907 [11:38:04<00:00,  4.70s/it]  \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "dataset_path = 'I:/balanced_vggface2'\n",
    "\n",
    "os.makedirs(os.path.join(dataset_path, 'embeddings', 'train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_path, 'embeddings', 'test'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_path, 'embeddings', 'val'), exist_ok=True)\n",
    "\n",
    "for d in tqdm(keys):\n",
    "    image_list = []\n",
    "    for img_path in all_ids_dict[d]['train']:\n",
    "        img = Image.open(img_path)\n",
    "        x_train = tf.image.resize(np.array(img), (112, 112), method=\"nearest\")\n",
    "        x_train = (tf.cast(x_train, tf.float32) - 127.5) / 128.\n",
    "        x_train = tf.transpose(x_train, perm=[2, 0, 1])\n",
    "        x_train = tf.expand_dims(x_train, 0)\n",
    "        image_list.extend(x_train)\n",
    "\n",
    "    for img_path in all_ids_dict[d]['test']: \n",
    "        img = Image.open(img_path)\n",
    "        x_test = tf.image.resize(np.array(img), (112, 112), method=\"nearest\")\n",
    "        x_test = (tf.cast(x_test, tf.float32) - 127.5) / 128.\n",
    "        x_test = tf.transpose(x_test, perm=[2, 0, 1])\n",
    "        x_test = tf.expand_dims(x_test, 0)\n",
    "        image_list.extend(x_test)\n",
    "\n",
    "    for img_path in all_ids_dict[d]['val']: \n",
    "        img = Image.open(img_path)\n",
    "        x_val = tf.image.resize(np.array(img), (112, 112), method=\"nearest\")\n",
    "        x_val = (tf.cast(x_val, tf.float32) - 127.5) / 128.\n",
    "        x_val = tf.transpose(x_val, perm=[2, 0, 1])\n",
    "        x_val = tf.expand_dims(x_val, 0)\n",
    "        image_list.extend(x_val)\n",
    "        \n",
    "    id_emb = tf_rep.run(np.array(image_list))._0\n",
    "    np.savez_compressed(os.path.join(dataset_path, 'embeddings', 'train', d + '.npz'), res=id_emb[:20])\n",
    "    np.savez_compressed(os.path.join(dataset_path, 'embeddings', 'test', d + '.npz'), res=id_emb[20:25])\n",
    "    np.savez_compressed(os.path.join(dataset_path, 'embeddings', 'val', d + '.npz'), res=id_emb[25:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcface-tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7e022da480da49e336235f935b29fd28be2ae9e0f4ebe7bf3c5148e275c03b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
